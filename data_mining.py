# -*- coding: utf-8 -*-
"""Web_Mining

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m0MOoeunHIyyIkPh5X96BOAwJeKtnMJp
"""

# Import Libraries
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

# Libraries for Sentiment Analysis

from textblob import TextBlob
from nltk.util import ngrams
from nltk.classify import NaiveBayesClassifier
from nltk.corpus import subjectivity
from nltk.sentiment import SentimentAnalyzer
from nltk.sentiment.util import *
from nltk.sentiment.vader import SentimentIntensityAnalyzer

from google.colab import files

uploaded = files.upload()

# Read Data sets into the notebook
trump_df = pd.read_csv(r"hashtag_donaldtrump.csv",lineterminator='\n')

biden_df = pd.read_csv(r"hashtag_joebiden.csv",lineterminator='\n')

# Check shape of both data frames

print(trump_df.shape)

print(biden_df.shape)

# Check Info of both data sets
print(trump_df.info())

print(biden_df.info())

# Adding a new column to differentiate between tweets of Biden and Trump
trump_df["Class"] = "TRUMP"
biden_df["Class"] = "BIDEN"

# Concat the data frames(iki veriyi birlestirip,created at'e gore siraliyor)
Data_Mixed = pd.concat([trump_df,biden_df])
Data_Mixed.sort_values(by='created_at') # overt to datetime format
#df["created_at"] = pd.to_datetime(df.created_at)
Data_Mixed.head()

"""**CLEAN DATA**"""

#check for duplicates
print("Count of duplicates: {}".format(Data_Mixed.duplicated(subset=["tweet"]).sum()))

# Dropping all duplicates
print("Original size of Data_Mixed: {}".format(len(Data_Mixed)))
Data_Mixed.drop_duplicates(subset=["tweet"], inplace=True, keep=False)
print("No duplicates size of Data_Mixed : {}".format(len(Data_Mixed)))

def clean(text):
    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation
    and remove words containing numbers.'''
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    text=re.sub(r'@[A-Za-z0-9]+','',text)
    text=re.sub(r'#','',text)
    text=re.sub(r'RT[\s]+','',text)
    text=re.sub(r'[^\w]', ' ', text)
    return text

Data_Mixed['tweet']= Data_Mixed['tweet'].apply(lambda x: clean(x))

Data_Mixed.head(10)

"""**OUR ANALYSIS**"""

# Comparison of likes
Data_Mixed.groupby('Class')['likes'].sum().plot.bar()
plt.ylabel('Number of Likes')
plt.title('Trump vs Biden')
plt.show()

"""**-When we look at the graph above, we see that the number of likes for tweets about Biden is higher. This shows that Biden is talked about more than Trump.**"""

# Comparison of retweets
Data_Mixed.groupby('Class')['retweet_count'].sum().plot.bar()
plt.ylabel('Number of Retweets')
plt.title('Trump vs Biden')
plt.show()

"""**-When we compare the tweets according to the number of retweets this time, we can say that the tweets about Biden are retweeted more and reach more people**"""

Data_Mixed.country.value_counts()

Data_Mixed['country']=Data_Mixed['country'].replace({"United States of America" : "US", "United States" : "US"})

Data_Mixed.country.value_counts()

# Countries with highest number of tweets
plt.figure(figsize=(10,5))
Data_Mixed.groupby('country')['tweet'].count().sort_values(ascending=False).head(10).plot.bar()
plt.ylabel('Number of Twwets')
plt.title('Top Countries with highest number of tweets')
plt.show()

"""**-As expected more Tweets are from US, as elections are being conducted there**"""

# List of top 10 countries with highest number of tweets
top10Countries = Data_Mixed.groupby('country')['tweet'].count().sort_values(ascending=False).head(10).index.tolist()

# Twwets for Biden and Trump from each country
tweet_df = Data_Mixed.groupby(['country','Class'])['tweet'].count().reset_index()

tweet_df = tweet_df[tweet_df['country'].isin(top10Countries)]

tweet_df

#Plot top 10 countries with highest number of tweets for trump and biden
plt.figure(figsize=(20,8))
sns.barplot(data=tweet_df,x='country',y='tweet',hue='Class')
plt.show()

"""**-Except in US Most of countries tweets more about Trump**"""

country="France"
a=Data_Mixed[Data_Mixed.country==country].groupby('Class').tweet.count()
a.plot(x='Class', y="tweet", kind="pie", title = "tweet count in country 'France'")

country="US"
a=Data_Mixed[Data_Mixed.country==country].groupby('Class').tweet.count()
a.plot(x='Class', y="tweet", kind="pie", title = "tweet count in country 'US'")

# List of top 10 states with highest number of tweets
top10States = Data_Mixed.groupby('state')['tweet'].count().sort_values(ascending=False).head(10).index.tolist()

# Twets for Biden and Trump from each state in top10 states
state_df = Data_Mixed.groupby(['state','Class'])['tweet'].count().reset_index()

state_df = state_df[state_df['state'].isin(top10States)]

state_df

#Plot top 10 states with highest number of tweets for trump and biden
plt.figure(figsize=(20,8))
sns.barplot(data=state_df,x='state',y='tweet',hue='Class')
plt.show()

"""**-When analysing the top 10 states, we see that the tweets are more for Trump than Biden.**"""

state="Texas"
a=Data_Mixed[Data_Mixed.state==state].groupby('Class').tweet.count()
a.plot(x='Class', y="tweet", kind="pie", title = "tweet count in state 'Texas'")

state="Oregon"
a=Data_Mixed[Data_Mixed.state==state].groupby('Class').tweet.count()
a.plot(x='Class', y="tweet", kind="pie", title = "tweet count in state 'Oregon'")

# List of top 10 cities with highest number of tweets
top10Cities = Data_Mixed.groupby('city')['tweet'].count().sort_values(ascending=False).head(10).index.tolist()

# Twets for Biden and Trump from each city in top10 cities
city_df = Data_Mixed.groupby(['city','Class'])['tweet'].count().reset_index()

city_df = city_df[city_df['city'].isin(top10Cities)]

city_df

#Plot top 10 cities with highest number of tweets for trump and biden
plt.figure(figsize=(20,8))
sns.barplot(data=city_df,x='city',y='tweet',hue='Class')
plt.show()

# List of top 5 continents with highest number of tweets
top5continents = Data_Mixed.groupby('continent')['tweet'].count().sort_values(ascending=False).head(5).index.tolist()

# Twets for Biden and Trump from each continents in top5 continents
continent_df = Data_Mixed.groupby(['continent','Class'])['tweet'].count().reset_index()

continent_df = continent_df[continent_df['continent'].isin(top5continents)]

continent_df

#Plot top 5 continents with highest number of tweets for trump and biden
plt.figure(figsize=(20,8))
sns.barplot(data=continent_df,x='continent',y='tweet',hue='Class')
plt.show()

"""**-As expected, more elections were discussed in North America.**"""

top_10_trump_followers = Data_Mixed[Data_Mixed["Class"] == "TRUMP"]\
    .sort_values(by="user_followers_count", ascending=False)\
    .head(10)[["user_name", "user_followers_count"]]

for index, row in top_10_trump_followers.iterrows():
    user_name = row["user_name"]
    follower_count = row["user_followers_count"]
    print(f"User Name: {user_name} - Follower Count: {follower_count}")

Data_Mixed["user_followers_count"].fillna(0, inplace=True)

for column in Data_Mixed.columns:
    # Eksik değer sayısını kontrol etme
    missing_values = Data_Mixed[column].isnull().sum()

    if missing_values > 0:
        print(f"Sütun: {column}")
        print(f"Eksik Değer Sayısı: {missing_values}")

#biden icin user_followers_count objectti, o yüzden bu degiskenin tipini numeric yaptik
Data_Mixed["user_followers_count"] = pd.to_numeric(Data_Mixed["user_followers_count"], errors="coerce")

fig, (ax1, ax2) = plt.subplots(2,1, figsize=(10, 16), sharex=True)
sns.barplot(x="user_followers_count", y="user_name", orient="h", ax=ax1, palette=["r"],
           data=Data_Mixed[(Data_Mixed.Class == "TRUMP")]\
           .drop_duplicates(subset=["user_name"])\
           .sort_values(by=["user_followers_count"], ascending=False)[["user_name", "user_followers_count"]][:10])
ax1.set_title('People with Highest Followers who class TRUMP')

sns.barplot(x="user_followers_count", y="user_name", orient="h", ax=ax2, palette=["b"],
           data=Data_Mixed[(Data_Mixed.Class == "BIDEN")]
           .drop_duplicates(subset=["user_name"])\
           .sort_values(by=["user_followers_count"], ascending=False)[["user_name", "user_followers_count"]][:10])
ax2.set_title('People with Highest Followers who class BIDEN')
fig.show()

"""**Data Training**

-----Naive Bayes-----
"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB


X = Data_Mixed["tweet"]
y = Data_Mixed["Class"]



vectorizer = CountVectorizer()
X_vectorized = vectorizer.fit_transform(X)



X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)


nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)


y_pred = nb_model.predict(X_test)

nb_accuracy = (y_pred == y_test).mean()
print("Accuracy:", nb_accuracy)

"""**Here, we train the Naive Bayes classification model. After making predictions on the test set, we calculate the accuracy rate. According to our calculations, Accuracy: 0.93759, which shows that our model has a correct prediction rate of 93%.**

----- KNN Algorithm -----
"""

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier


X2 = Data_Mixed["tweet"]
y2 = Data_Mixed["Class"]


vectorizer = CountVectorizer()
X_vectorized2 = vectorizer.fit_transform(X)


X_train2, X_test2, y_train2, y_test2 = train_test_split(X_vectorized2, y2, test_size=0.2, random_state=42)


knn_model = KNeighborsClassifier()
knn_model.fit(X_train2, y_train2)


y_pred2 = knn_model.predict(X_test2)

knn_accuracy = (y_pred2 == y_test2).mean()
print("Accuracy:", knn_accuracy)

"""**-Here, we train the K-nn classification model. After predicting on the test set, we calculate the accuracy rate. According to our calculations, Accuracy: 0.94353, which shows that the correct prediction rate of our model is 94%.**"""

#COMPARISON
algorithms = ["K-NN", "Naive Bayes"]
accuracies = [knn_accuracy, nb_accuracy]
plt.bar(algorithms, accuracies)
plt.xlabel("Algorithms")
plt.ylabel("Accuracy")
plt.title("Comparison of Classification Algorithms")
plt.show()

"""**-When we compare the two algorithms, we see that although the accuracy rate of both algorithms is very close, numerically, the data set trained with the k-nn algorithm is more accurate.**"""

ax = sns.stripplot(data=Data_Mixed[Data_Mixed.user_followers_count < Data_Mixed.user_followers_count.quantile(.999)].drop_duplicates(subset=["user_id"]), palette=["r", "b"],
                  x="user_followers_count",
                  y="Class")
ax.set_title("User Follower counts")

"""**-When we compare the tweet densities according to the number of user follower count, the account with the highest number of followers tweeting about Biden has 1.7k followers, while this number is 1.0k for the Trump. Accordingly, the tweet about Biden is expected to create more echo.**"""

ax = sns.stripplot(data=Data_Mixed[Data_Mixed.retweet_count < Data_Mixed.retweet_count.quantile(.999)].drop_duplicates(subset=["user_id"]), palette=["r", "b"],
                  x="retweet_count",
                  y="Class")
ax.set_title("Retweet counts")

"""**-When we compare the tweet densities according to the number of retweets, the highest number of retweets received by the tweet about biden is more than 300, while this number is 250 for trump. Accordingly, the tweet about Biden is expected to create more echo.**"""

ax= sns.stripplot(data=Data_Mixed[Data_Mixed.likes < Data_Mixed.likes.quantile(.999)].drop_duplicates(subset=["user_id"]), palette=["r", "b"],
                 x="likes",
                 y="Class")
ax.set_title("Likes count")

"""**-When we compare the tweet densities according to the number of likes, the highest number of likes received by the tweet about biden is around 600, while this number is around 500 for trump. Accordingly, the tweet about biden is expected to create more echo.**"""

def clean(text):
    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation
    and remove words containing numbers.'''
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    text=re.sub(r'@[A-Za-z0-9]+','',text)
    text=re.sub(r'#','',text)
    text=re.sub(r'RT[\s]+','',text)
    text=re.sub(r'[^\w]', ' ', text)
    return text

# create fuction to get the subjectivity and polarity
def getSubjectivity(text):
    return TextBlob(text).sentiment.subjectivity
def getPolarity(text):
    return TextBlob(text).sentiment.polarity
def getAnalysis(score):
    if score < 0:
        return 'negative'
    elif score==0:
        return 'neutral'
    else:
        return 'positive'

Trump_Tweets = Data_Mixed.query('(Class == "TRUMP")').sort_values('user_followers_count',ascending = False).drop_duplicates(['user_name'])[['tweet','country']]
Trump_Tweets = Trump_Tweets.dropna().loc[Trump_Tweets.country == 'US']

Trump_Tweets.reset_index(inplace = True, drop = True)

Trump_Tweets['ClearTweet'] = Trump_Tweets['tweet'].apply(clean)

Trump_Tweets['subjectivity']= Trump_Tweets['ClearTweet'].apply(getSubjectivity)
Trump_Tweets['polarity']    = Trump_Tweets['ClearTweet'].apply(getPolarity)
Trump_Tweets['analysis']    = Trump_Tweets['polarity'].apply(getAnalysis)


Trump_Tweets.head()

Trump_Tweets.analysis.value_counts(normalize=True)*100

# Plot graph for analysis of Trump Tweets
plt.figure(figsize=(10,5))
(Trump_Tweets.analysis.value_counts(normalize=True)*100).plot.bar()
plt.ylabel("%age of tweets")
plt.show()

"""**-According to sentiment analysis data for Trump, neutral tweet was obtained with 35.70%, positive tweet with 35.70% and negative tweet with 28.60%.**"""

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
def word_cloud(wd_list):
    stopwords = set(STOPWORDS)
    all_words = ' '.join([text for text in wd_list])
    wordcloud = WordCloud(
        background_color='white',
        stopwords=stopwords,
        width=1600,
        height=800,
        random_state=1,
        colormap='jet',
        max_words=80,
        max_font_size=200).generate(all_words)
    plt.figure(figsize=(12, 10))
    plt.axis('off')
    plt.imshow(wordcloud, interpolation="bilinear");
word_cloud(trump_df['tweet'][:5000])

Biden_Tweets = Data_Mixed.query('(Class == "BIDEN")').sort_values('user_followers_count',ascending = False).drop_duplicates(['user_name'])[['tweet','country']]
Biden_Tweets = Biden_Tweets.dropna().loc[Biden_Tweets.country == 'US']


Biden_Tweets.reset_index(inplace = True, drop = True)

Biden_Tweets['ClearTweet'] = Biden_Tweets['tweet'].apply(clean)


Biden_Tweets['subjectivity']= Biden_Tweets['ClearTweet'].apply(getSubjectivity)
Biden_Tweets['polarity']    = Biden_Tweets['ClearTweet'].apply(getPolarity)
Biden_Tweets['analysis']    = Biden_Tweets['polarity'].apply(getAnalysis)
Biden_Tweets.head()


Biden_Tweets.head()

Biden_Tweets.analysis.value_counts(normalize=True)*100

# Plot graph for analysis of Biden Tweets
plt.figure(figsize=(10,5))
(Biden_Tweets.analysis.value_counts(normalize=True)*100).plot.bar()
plt.ylabel("%age of tweets")
plt.show()

"""**-According to sentiment analysis data for Biden, it is seen that there is neutral tweet with a rate of 45.34%, positive tweet with a rate of 35.26% and negative tweet with a rate of 19.40%.**"""

from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
def word_cloud(wd_list):
    stopwords = set(STOPWORDS)
    all_words = ' '.join([str(text) for text in wd_list])
    wordcloud = WordCloud(
        background_color='white',
        stopwords=stopwords,
        width=1600,
        height=800,
        random_state=1,
        colormap='jet',
        max_words=80,
        max_font_size=200).generate(all_words)
    plt.figure(figsize=(12, 10))
    plt.axis('off')
    plt.imshow(wordcloud, interpolation="bilinear");
word_cloud(biden_df['tweet'][0:5000])

import pandas as pd
import matplotlib.pyplot as plt

# Biden ve Trump için sentiment analizi sonuçlarından oluşan DataFrame oluşturma
biden_sentiment = Biden_Tweets['analysis'].value_counts(normalize=True) * 100
trump_sentiment = Trump_Tweets['analysis'].value_counts(normalize=True) * 100

# Karşılaştırma için yeni bir DataFrame oluşturma
overall_sent = pd.DataFrame({
    'Trump Tweets': trump_sentiment,
    'Biden Tweets': biden_sentiment
})

# Grafik oluşturma
overall_sent.plot(kind='bar', figsize=(10, 7))
plt.title('Sentiment Analysis Comparison: Trump vs Biden')
plt.xlabel('Sentiment')
plt.ylabel('%age of tweets')
plt.show()

"""**-Based on these data, it can be concluded that the neutrality rate for Biden is slightly higher than for Trump, but positive and negative tweet for both politicians shows a similar distribution.**"""

X = Data_Mixed["tweet"]
y = Data_Mixed["Class"]

#Metin verilerini vektörlere dönüştürme
vectorizer = CountVectorizer()
X_vectorized = vectorizer.fit_transform(X)

#Eğitim ve test setlerine ayırma
X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)

#K-NN sınıflandırma modelini eğitme
knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)

#Yeni veri örneği
new_tweet = "I love Trump"

# Duygusal analizi yapma
blob = TextBlob(new_tweet)
sentiment = blob.sentiment.polarity

#Yeni veriyi vektöre dönüştürme
new_tweet_vectorized = vectorizer.transform([new_tweet])

#Yeni veriyi kullanarak tahmin yapma
prediction = knn_model.predict(new_tweet_vectorized)

# Tahmin sonucunu çıktı olarak yazdırma
if sentiment > 0:
    if prediction[0] == "BIDEN":
        print("Predicted Class: Biden")
    elif prediction[0] == "TRUMP":
        print("Predicted Class: Trump")
elif sentiment < 0:
    if prediction[0] == "TRUMP":
        print("Predicted Class: BIDEN")
    elif prediction[0] == "BIDEN":
        print("Predicted Class: TRUMP")
else:
    print("Predicted Class:", prediction[0])